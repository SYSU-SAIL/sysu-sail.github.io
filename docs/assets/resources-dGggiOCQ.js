import{l as k,r as m,d as B,q as v,v as H,x as s,C as t,z as e,J as E,M as w,X,Y as S,W as C,w as R,t as x,K as z,L as q,a0 as J,a1 as Q}from"./index-BJfYvVzk.js";import{E as Z,a as ee}from"./anchor-link-GaWleC0q.js";import{E as A,_ as I}from"./_plugin-vue_export-helper-CobECD_a.js";import{E as te}from"./button-CpKGfYZF.js";import"./raf-Cbk8d58K.js";const se=[{name:"ContextCapture",person:"张勇健",img:"/./resources/sw_ContextCapture.jpg",url:"https://bentleybsy.wpengine.com/software/itwin-capture-modeler/",num:"1套",intro:"三维重建软件，支持导入图像序列进行稠密三维重建，可以加入GPS信息，新版本软件名为iTwin Capture"},{name:"多传感器信号仿真系统",person:"高平海",img:"",url:"",num:"1套",intro:"激光雷达、可见光相机、红外相机、毫米波雷达等多种传感器联合仿真"}],ae=[{name:"Flickr1024",person:"王龙光",img:"/./resources/dataset_flickr1024.jpg",url:"https://yingqianwang.github.io/Flickr1024/",num:"2.5GB(压缩包)",intro:"首个双目图像超分辨数据集"},{name:"Lunar-CV",person:"管玮珺",img:"",url:"https://link.springer.com/article/10.1007/s44267-024-00045-y",num:"3GB",intro:"首个月球环境跨视角定位数据集。"},{name:"RAECD",person:"高平海",img:"/./resources/dataset_raecd.png",url:"",num:"13GB",intro:"利用机械臂采集的DAVIS 346C事件相机数据集，用于评估事件相机视频重建性能。"},{name:"SensatUrban",person:"刘砚",img:"/./resources/dataset_sensaturban.png",url:"https://github.com/QingyongHu/SensatUrban?tab=readme-ov-file",num:"30GB(压缩包)",intro:"通过无人机在英国的伯明翰，剑桥采集的城市规模点云数据集。"},{name:"Aachen-Day-Night",person:"李坤洪",img:"/./resources/dataset_Aachen_day_night.png",url:"https://arxiv.org/pdf/2005.05179",num:"12.5GB",intro:"室外真实场景匹配和定位数据集，提供RGB图像、相机内外参、colmap重建点云"},{name:"Appolo-stereo",person:"李坤洪",img:"/./resources/dataset_Appolo.jpg",url:"https://apolloscape.auto/stereo.html",num:"29GB",intro:"自动驾驶场景双目立体匹配数据集，提供RGB图像、相机内参、前背景mask"},{name:"Argoverse-stereo",person:"李坤洪",img:"/./resources/dataset_argoverse.jpg",url:"https://www.argoverse.org/av1.html",num:"15GB(压缩包)",intro:"自动驾驶场景双目立体匹配数据集，提供RGB图像、相机内参"},{name:"Blended-MVS",person:"李坤洪",img:"/./resources/dataset_blended_mvs.jpg",url:"https://github.com/YoYo000/BlendedMVS",num:"230GB",intro:"渲染的真实场景三维重建数据集，提供RGB图像、深度图和相机内外参"},{name:"CRE-stereo",person:"李坤洪",img:"/./resources/dataset_cre_stereo.jpg",url:"https://github.com/megvii-research/CREStereo",num:"383GB",intro:"仿真双目立体匹配数据集，提供RGB格式的双目图像对、立体匹配真值，不带相机参数"},{name:"ETH3D-stereo",person:"李坤洪",img:"/./resources/dataset_eth3d.jpg",url:"https://www.eth3d.net/",num:"106MB",intro:"室内外真实场景双目立体匹配数据集，提供RGB双目图像对、半稠密立体匹配真值"},{name:"FallingThings-stereo",person:"李坤洪",img:"/./resources/dataset_falling_things.jpg",url:"https://research.nvidia.com/publication/2018-06_falling-things-synthetic-dataset-3d-object-detection-and-pose-estimation",num:"87GB",intro:"渲染的室内外场景数据集，仅下载了对应的RGB与深度图"},{name:"HR_VS-stereo",person:"李坤洪",img:"/./resources/dataset_HR_VS.jpg",url:"https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Hierarchical_Deep_Stereo_Matching_on_High-Resolution_Images_CVPR_2019_paper.html",num:"38GB",intro:"渲染的自动驾驶场景数据集"},{name:"Hypersim",person:"李坤洪",img:"/./resources/dataset_hypersim.jpg",url:"https://github.com/apple/ml-hypersim",num:"35GB",intro:"渲染的室内场景数据集，提供了包括深度、法向量等几何数据、相机参数，仅下载了RGB图像、相机参数和深度图"},{name:"InLoc",person:"李坤洪",img:"/./resources/dataset_InLoc.jpg",url:"https://github.com/HajimeTaira/InLoc_dataset",num:"449GB(压缩包)",intro:"室内真实场景数据集，提供了点云、高分辨率RGB图像和相机位姿"},{name:"Instereo2K",person:"李坤洪",img:"/./resources/dataset_Instereo2K.jpg",url:"https://github.com/YuhuaXu/StereoDataset",num:"17GB",intro:"室内真实场景立体匹配数据集，提供RGB和视差值，不带相机参数"},{name:"KITTI2012-stereo",person:"李坤洪",img:"/./resources/dataset_kitti_12.jpg",url:"https://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=stereo",num:"1.7GB",intro:"自动驾驶场景双目立体匹配数据集，提供RGB和灰度格式的双目图像对、相机标定参数、点云转化得到的立体匹配真值和光流真值"},{name:"KITTI2015-stereo",person:"李坤洪",img:"/./resources/dataset_kitti_15.jpg",url:"https://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=stereo",num:"1.7GB",intro:"自动驾驶场景双目立体匹配数据集，提供RGB和灰度格式的双目图像对、相机标定参数、点云转化得到的立体匹配真值和光流真值"},{name:"MegaDepth",person:"李坤洪",img:"/./resources/dataset_megadepth.png",url:"https://www.cs.cornell.edu/projects/megadepth/",num:"915GB",intro:"真实场景数据集，提供了RGB图像、colmap重建的点云、深度图、相机内外参"},{name:"Middlebury-stereo",person:"李坤洪",img:"/./resources/dataset_middlebury.jpg",url:"https://vision.middlebury.edu/stereo/data/",num:"7.1GB",intro:"室内真实场景立体匹配数据集，提供了RGB图像、视差真值、相机内外参，下载了Eval3、2014、2021mobile三个子集"},{name:"MPISintel-stereo",person:"李坤洪",img:"/./resources/dataset_MPI_sintel.jpg",url:"http://sintel.is.tue.mpg.de/",num:"2.5GB",intro:"渲染数据集，提供了RGB图像、视差真值、光流真值，下载了视差和图像部分"},{name:"NYUDepth_v2",person:"李坤洪",img:"/./resources/dataset_nyu_depth_v2.jpg",url:"https://cs.nyu.edu/~fergus/datasets/nyu_depth_v2.html",num:"6GB",intro:"室内真实场景数据集，提供了RGB图像、深度真值和分割，下载了深度和图像部分"},{name:"ScnaNet",person:"李坤洪",img:"/./resources/dataset_scannet.jpg",url:"http://www.scan-net.org/",num:"1.2TB(压缩包)",intro:"室内真实场景数据集，提供了RGB图像、深度真值和点云分割，下载了scans1-1400"},{name:"SceneFlow",person:"李坤洪",img:"/./resources/dataset_scene_flow.jpg",url:"https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html",num:"272GB",intro:"仿真数据集，提供了RGB图像、视差真值"},{name:"Spring",person:"李坤洪",img:"/./resources/dataset_spring.jpg",url:"https://spring-benchmark.org/",num:"216GB(压缩包)",intro:"仿真数据集，提供了RGB图像、视差、光流、场景流真值和相机内外参"},{name:"TartanAir",person:"李坤洪",img:"/./resources/dataset_tartanair.jpg",url:"https://theairlab.org/tartanair-dataset/",num:"1.3TB",intro:"仿真数据集，提供了RGB图像、深度真值和相机内外参"},{name:"Unreal4K",person:"李坤洪",img:"/./resources/dataset_unreal4K.jpg",url:"https://github.com/CVLAB-Unibo/neural-disparity-refinement",num:"836GB",intro:"仿真数据集，提供了RGB图像、视差真值和相机内外参"},{name:"VirtualKITTI2",person:"李坤洪",img:"/./resources/dataset_vkitti2.jpg",url:"https://arxiv.org/pdf/2001.10773",num:"15GB",intro:"自动驾驶仿真数据集，提供了RGB图像、视差真值和相机内外参，每个场景都仿真了不同天气、相机视角变化的情况"}],oe={class:"info-image"},re=["src"],ne={class:"info-content"},ie={class:"info-name"},le={class:"info-person"},ce={class:"info-num"},de={class:"info-intro"},ue=k({__name:"ResourceItem",props:{img:String,person:String,name:String,url:String,num:String,intro:String,height:{type:Number,default:100}},setup(r){const a=r,d=c=>{window.open(c,"_blank")},p=m("."),g=B(()=>a.img?a.img:`/${p.value}/resources/no_img.jpg`);return(c,l)=>{const u=S,_=te,i=C,j=A;return v(),H(j,{style:E(`height: ${r.height}px`),class:"shadow"},{default:s(()=>[t(i,{gutter:2},{default:s(()=>[t(u,{span:8},{default:s(()=>[e("div",oe,[e("img",{src:g.value,width:"100%",style:E({"max-height":`${.55*r.height}px`,"object-fit":"fill"})},null,12,re)])]),_:1}),t(u,{span:16},{default:s(()=>[e("div",ne,[e("p",ie,w(r.name),1),e("p",le,w(r.person),1),e("p",ce,w(r.num),1),t(_,{size:"small",class:"more-btn",type:"primary",plain:"",disabled:!r.url,onClick:l[0]||(l[0]=D=>d(r.url))},{default:s(()=>l[1]||(l[1]=[X(" 相关链接 ")])),_:1},8,["disabled"])])]),_:1})]),_:1}),t(i,null,{default:s(()=>[t(u,{span:24},{default:s(()=>[e("div",de,[e("span",null,w(r.intro),1)])]),_:1})]),_:1})]),_:1},8,["style"])}}}),me=I(ue,[["__scopeId","data-v-3edc5916"]]),pe={class:"resource-category"},ge={class:"card-header"},_e={class:"title_text"},he=k({__name:"ResourceCategory",props:{category:{type:Object,default:()=>({title:"",data:[]})}},setup(r){const a=m(null),d=m(100),p=()=>a.value?a.value.offsetWidth*.15:d.value,g=B(()=>p());return R(g,c=>{d.value=c},{immediate:!0}),(c,l)=>{const u=S,_=C;return v(),x("div",pe,[e("div",ge,[l[0]||(l[0]=e("div",{class:"title_bar"},null,-1)),e("span",_e,w(r.category.title),1)]),e("div",{class:"card-body",style:{"margin-top":"15px"},ref_key:"catRowDiv",ref:a},[t(_,{gutter:20},{default:s(()=>[(v(!0),x(z,null,q(r.category.data,i=>(v(),H(u,{span:6,style:{"margin-bottom":"20px"}},{default:s(()=>[t(me,{name:i.name,person:i.person,img:i.img,url:i.url,num:i.num,intro:i.intro,height:d.value},null,8,["name","person","img","url","num","intro","height"])]),_:2},1024))),256))]),_:1})],512)])}}}),T=I(he,[["__scopeId","data-v-0d7f573d"]]),fe={id:"hardware"},we={id:"software"},ve={id:"dataset"},be=k({__name:"resources",setup(r){const a=m("."),d=`/${a.value}/resources/hw_a100_resize.jpg`,p=`/${a.value}/resources/hw_v100_resize.jpg`,g=`/${a.value}/resources/hw_4090_resize.png`,c=`/${a.value}/resources/hw_3090_resize.png`,l=`/${a.value}/resources/hw_DJI_M300_RTK_resize.jpg`,u=`/${a.value}/resources/hw_faro_resize.jpg`,_=`/${a.value}/resources/hw_lidarcar_resize.jpg`,i=`/${a.value}/resources/hw_RIEGL_resize.jpg`,j=`/${a.value}/resources/hw_robot_resize.jpg`,D=`/${a.value}/resources/hw_robot2_resize.jpg`,V=`/${a.value}/resources/hw_robot3_resize.jpg`,M=`/${a.value}/resources/hw_robot4_resize.jpg`,G=m(null),$=m(100),L=m(100),K=()=>G.value?G.value.offsetWidth*.1:$.value,N=B(()=>K());R(N,h=>{$.value=h},{immediate:!0});const P=B(()=>1.3*$.value);R(P,h=>{L.value=h});const F={title:"软件资源",data:se},Y={title:"数据资源",data:ae};return(h,o)=>{const f=A,b=Z,U=ee,O=J,n=S,y=C,W=Q;return v(),x(z,null,[t(O,{position:"fixed",style:{height:"100%","margin-top":"0px"}},{default:s(()=>[t(U,{offset:70,style:{height:"100%","text-align":"left","background-color":"#ffffff"}},{default:s(()=>[t(b,{href:"#server"},{default:s(()=>[t(f,{class:"shadow"},{default:s(()=>o[0]||(o[0]=[e("span",{class:"link-text"},"计算资源",-1)])),_:1})]),_:1}),t(b,{href:"#hardware"},{default:s(()=>[t(f,{class:"shadow"},{default:s(()=>o[1]||(o[1]=[e("span",{class:"link-text"},"硬件资源",-1)])),_:1})]),_:1}),t(b,{href:"#software"},{default:s(()=>[t(f,{class:"shadow"},{default:s(()=>o[2]||(o[2]=[e("span",{class:"link-text"},"软件资源",-1)])),_:1})]),_:1}),t(b,{href:"#dataset"},{default:s(()=>[t(f,{class:"shadow"},{default:s(()=>o[3]||(o[3]=[e("span",{class:"link-text"},"数据资源",-1)])),_:1})]),_:1})]),_:1})]),_:1}),t(W,{class:"main"},{default:s(()=>[t(y,{style:{"margin-top":"20px"},gutter:10},{default:s(()=>[t(f,{class:"info_card",shadow:"always"},{default:s(()=>[e("div",{id:"server",ref_key:"catRowDiv",ref:G},[o[4]||(o[4]=e("div",{class:"card-header"},[e("div",{class:"title_bar"}),e("span",{class:"title_text"},"计算资源")],-1)),o[5]||(o[5]=e("div",{class:"card-body"},"实验室拥有80G显存计算显卡、英伟达V100、TITAN RTX、4090、3090、2080Ti等系列计算显卡及服务器，可为AI模型训练提供有效算力支撑。",-1)),t(y,{type:"flex","align-item":"middle"},{default:s(()=>[t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:d,width:"100%",style:{"object-fit":"fill"}})])]),_:1}),t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:p,width:"100%",style:{"object-fit":"fill"}})])]),_:1}),t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:g,width:"100%",style:{"object-fit":"fill"}})])]),_:1}),t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:c,width:"100%",style:{"object-fit":"fill"}})])]),_:1})]),_:1})],512),e("div",fe,[o[6]||(o[6]=e("div",{class:"card-header"},[e("div",{class:"title_bar"}),e("span",{class:"title_text"},"硬件资源")],-1)),o[7]||(o[7]=e("div",{class:"card-body"},"实验室拥有RIEGL、FARO、速腾聚创、Ouster、大疆等厂家的全谱系车载与机载激光扫描设备，购置了配备高精度激光扫描系统、GPS/惯导系统、全景/单反/红外相机的车载多模态移动扫描平台，可为多模态数据获取提供有力支撑。",-1)),t(y,{type:"flex",align:"middle"},{default:s(()=>[t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:l,width:"100%",style:{"object-fit":"fill"}})])]),_:1}),t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:_,width:"100%",style:{"object-fit":"fill"}})])]),_:1}),t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:u,width:"100%",style:{"object-fit":"fill"}})])]),_:1}),t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:i,width:"100%",style:{"object-fit":"fill"}})])]),_:1})]),_:1}),o[8]||(o[8]=e("div",{class:"card-body"},"实验室拥有履带式机器人、轮式机器人、四足机器人、无人机、机械臂、灵巧手、夹爪等执行设备，可为机器人开发、测试与调试提供平台支撑。",-1)),t(y,{type:"flex",align:"middle"},{default:s(()=>[t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:j,width:"100%",style:{"object-fit":"fill"}})])]),_:1}),t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:D,width:"100%",style:{"object-fit":"fill"}})])]),_:1}),t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:V,width:"100%",style:{"object-fit":"fill"}})])]),_:1}),t(n,{span:6,class:"col-img"},{default:s(()=>[e("div",{class:"shadow2"},[e("img",{src:M,width:"100%",style:{"object-fit":"fill"}})])]),_:1})]),_:1})]),e("div",we,[t(T,{category:F})]),e("div",ve,[t(T,{category:Y})])]),_:1})]),_:1})]),_:1})],64)}}}),Re=I(be,[["__scopeId","data-v-a0ff3247"]]);export{Re as default};
